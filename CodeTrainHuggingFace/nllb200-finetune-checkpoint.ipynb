{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Our Training Strategy: Why We Use Checkpoints\n",
    "**Efficient Resource Management:** Training an entire model in one go can easily exhaust GPU memory or take an incredibly long time. By checkpointing, we train in smaller segments, which allows for more efficient use of our available resources for each chunk.\n",
    "\n",
    "**Seamless Resumption:** Imagine your training gets interrupted—perhaps due to a power outage, a system crash, or simply needing to free up the GPU for another task. Without checkpoints, you'd lose all your hard-earned progress. With them, we can resume training from the last saved point, saving immense time and effort.\n",
    "\n",
    "**Better Monitoring & Adjustment:** Checkpoints provide specific points in time where we can save the model's entire state. This means we can:\n",
    "\n",
    "**Enhanced Stability:** For very deep or complex neural networks, continuous long-term training can sometimes lead to stability issues (e.g., exploding or vanishing gradients). Checkpointing provides natural breakpoints to ensure stability and allows for re-evaluation if needed.\n",
    "\n",
    "# How We Implement Checkpointing\n",
    "The process is straightforward and is a standard practice in most deep learning workflows:\n",
    "\n",
    "**Saving the Model's State:** At predefined intervals (e.g., after every 'X' epochs, or every 'Y' batches), we systematically save the model's current weights, the optimizer's state (which is crucial for continuing training properly), and any relevant hyperparameters or training configurations.\n",
    "\n",
    "**Loading the State:** When we need to continue training, we simply load the saved state from our latest checkpoint. This effectively brings the model and its entire training progression back to life exactly where it left off.\n",
    "\n",
    "Most modern deep learning frameworks, such as TensorFlow and PyTorch, offer robust and easy-to-use functionalities for saving and loading these checkpoints. This makes our training process much more resilient, flexible, and robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib torch torchvision\n",
    "!pip install pandas numpy\n",
    "!pip install transformers datasets accelerate sentencepiece evaluate sacrebleu\n",
    "!pip install tqdm\n",
    "!pip install langdetect fsspec==2025.3.0\n",
    "!pip install -U transformers[torch] accelerate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:00:04.442250Z",
     "iopub.status.busy": "2025-04-02T09:00:04.441690Z",
     "iopub.status.idle": "2025-04-02T09:00:14.996741Z",
     "shell.execute_reply": "2025-04-02T09:00:14.995832Z",
     "shell.execute_reply.started": "2025-04-02T09:00:04.442198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install gdown \n",
    "!gdown --id 1dh7uWJ8GnHbb-2aWpUuB3VCE5L4gRaCw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T22:41:36.324497Z",
     "iopub.status.busy": "2025-04-02T22:41:36.324093Z",
     "iopub.status.idle": "2025-04-02T22:42:06.291773Z",
     "shell.execute_reply": "2025-04-02T22:42:06.290926Z",
     "shell.execute_reply.started": "2025-04-02T22:41:36.324459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, EarlyStoppingCallback, Seq2SeqTrainingArguments ,AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from huggingface_hub import login\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:00:52.088153Z",
     "iopub.status.busy": "2025-04-02T09:00:52.087830Z",
     "iopub.status.idle": "2025-04-02T09:00:57.440763Z",
     "shell.execute_reply": "2025-04-02T09:00:57.440037Z",
     "shell.execute_reply.started": "2025-04-02T09:00:52.088129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:01:29.816523Z",
     "iopub.status.busy": "2025-04-02T09:01:29.816141Z",
     "iopub.status.idle": "2025-04-02T09:01:30.289669Z",
     "shell.execute_reply": "2025-04-02T09:01:30.288857Z",
     "shell.execute_reply.started": "2025-04-02T09:01:29.816495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trainDf = pd.read_csv('train.tsv',  sep='\\t', names = [\"src_lang\", \"src\", \"tgt\"])\n",
    "print(trainDf.head())\n",
    "print(f'Length: {len(trainDf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:01:51.173937Z",
     "iopub.status.busy": "2025-04-02T09:01:51.173566Z",
     "iopub.status.idle": "2025-04-02T09:01:51.336334Z",
     "shell.execute_reply": "2025-04-02T09:01:51.335439Z",
     "shell.execute_reply.started": "2025-04-02T09:01:51.173905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainDf = trainDf.dropna(subset=[\"src_lang\", \"src\", \"tgt\"])\n",
    "trainDf = trainDf[\n",
    "    (trainDf[\"src\"].str.strip() != \"\") &\n",
    "    (trainDf[\"tgt\"].str.strip() != \"\") &\n",
    "    (trainDf[\"src\"].str.len() > 5) &\n",
    "    (trainDf[\"tgt\"].str.len() > 5)\n",
    "]  \n",
    "trainDf = trainDf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:01:54.114267Z",
     "iopub.status.busy": "2025-04-02T09:01:54.113971Z",
     "iopub.status.idle": "2025-04-02T09:01:54.347507Z",
     "shell.execute_reply": "2025-04-02T09:01:54.346787Z",
     "shell.execute_reply.started": "2025-04-02T09:01:54.114245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Bước 1: Chia 80% train, 20% còn lại (temp)\n",
    "train_df, temp_df = train_test_split(trainDf, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bước 2: Chia temp tiếp thành 50% valid, 50% test (10% + 10%)\n",
    "valid_df, eval_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert sang HuggingFace Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)\n",
    "eval_ds  = Dataset.from_pandas(eval_df)\n",
    "\n",
    "print(\"✅ train:\", len(train_ds))\n",
    "print(\"✅ valid:\", len(valid_ds))\n",
    "print(\"✅ eval: \", len(eval_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:01:59.898271Z",
     "iopub.status.busy": "2025-04-02T09:01:59.897946Z",
     "iopub.status.idle": "2025-04-02T09:01:59.930323Z",
     "shell.execute_reply": "2025-04-02T09:01:59.929345Z",
     "shell.execute_reply.started": "2025-04-02T09:01:59.898245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for param in model.model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.model.encoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} is trainable\")\n",
    "    else:\n",
    "        print(f\"{name} is frozen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:02:04.041523Z",
     "iopub.status.busy": "2025-04-02T09:02:04.041176Z",
     "iopub.status.idle": "2025-04-02T09:02:04.047678Z",
     "shell.execute_reply": "2025-04-02T09:02:04.046702Z",
     "shell.execute_reply.started": "2025-04-02T09:02:04.041495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "      text = re.sub(r\"[^a-zA-ZÀ-ỹ0-9\\s.,?!:;()-]+\", \" \", text)\n",
    "      text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "      text = re.sub(r\"\\s+([.,?!:;()-])\", r\"\\1\", text)\n",
    "\n",
    "      text = re.sub(r\"^[()]+|[()]+$\", \"\", text).strip()\n",
    "\n",
    "      return text\n",
    "def preprocess(example):\n",
    "    try:\n",
    "        tokenizer.src_lang = example[\"src_lang\"]\n",
    "        tokenizer.tgt_lang = \"vie_Latn\"\n",
    "\n",
    "        encoded = tokenizer(\n",
    "            clean_text(example[\"src\"]),\n",
    "            text_target=clean_text(example[\"tgt\"]),\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=300\n",
    "        )\n",
    "\n",
    "        return encoded\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"❌ Lỗi:\", e)\n",
    "        print(\"Example:\", example)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:02:09.648910Z",
     "iopub.status.busy": "2025-04-02T09:02:09.648570Z",
     "iopub.status.idle": "2025-04-02T09:03:44.799141Z",
     "shell.execute_reply": "2025-04-02T09:03:44.798145Z",
     "shell.execute_reply.started": "2025-04-02T09:02:09.648881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(\"./nllb_train_processed\") and os.path.exists(\"./nllb_valid_processed\") and os.path.exists(\"./nllb_eval_processed\"):\n",
    "    train_ds = load_from_disk(\"./nllb_train_processed\")\n",
    "    valid_ds = load_from_disk(\"./nllb_valid_processed\")\n",
    "    eval_ds = load_from_disk(\"./nllb_eval_processed\")\n",
    "else:\n",
    "    # print(\"Error\")\n",
    "    train_ds = train_ds.map(preprocess, remove_columns=train_ds.column_names)\n",
    "    valid_ds = valid_ds.map(preprocess, remove_columns=valid_ds.column_names)\n",
    "    eval_ds = eval_ds.map(preprocess, remove_columns=eval_ds.column_names)\n",
    "\n",
    "    train_ds.save_to_disk(\"./nllb_train_processed\")\n",
    "    valid_ds.save_to_disk(\"./nllb_valid_processed\")\n",
    "    eval_ds.save_to_disk(\"./nllb_eval_processed\")\n",
    "\n",
    "print(len(train_ds))\n",
    "print(len(valid_ds))\n",
    "print(len(eval_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:03:47.689341Z",
     "iopub.status.busy": "2025-04-02T09:03:47.689013Z",
     "iopub.status.idle": "2025-04-02T09:03:47.898269Z",
     "shell.execute_reply": "2025-04-02T09:03:47.897574Z",
     "shell.execute_reply.started": "2025-04-02T09:03:47.689310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoardCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T09:03:50.911601Z",
     "iopub.status.busy": "2025-04-02T09:03:50.911297Z",
     "iopub.status.idle": "2025-04-02T09:03:52.146611Z",
     "shell.execute_reply": "2025-04-02T09:03:52.145809Z",
     "shell.execute_reply.started": "2025-04-02T09:03:50.911576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./nllb200-finetuned-checkpoints\",\n",
    "    logging_dir=\"./logs_file\",\n",
    "    \n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "\n",
    "    logging_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    # num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=2,\n",
    "\n",
    "    predict_with_generate=False,\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=False,\n",
    "    fp16=True,\n",
    "\n",
    "    max_steps=20000,\n",
    "    save_steps=500,\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    \n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T22:41:00.328997Z",
     "iopub.status.busy": "2025-04-02T22:41:00.328631Z",
     "iopub.status.idle": "2025-04-02T22:41:00.406175Z",
     "shell.execute_reply": "2025-04-02T22:41:00.405154Z",
     "shell.execute_reply.started": "2025-04-02T22:41:00.328969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "last_checkpoint = None\n",
    "\n",
    "if os.path.isdir(\"./nllb200-finetuned-checkpoints\"):\n",
    "    checkpoints = [os.path.join(\"./nllb200-finetuned-checkpoints\", d) for d in os.listdir(\"./nllb200-finetuned-checkpoints\") if d.startswith(\"checkpoint\")]\n",
    "\n",
    "    if checkpoints:\n",
    "        last_checkpoint = sorted(checkpoints, key = lambda x : int(x.split(\"-\")[-1]))[-1]\n",
    "\n",
    "if last_checkpoint:\n",
    "    print(f\"Resuming from {last_checkpoint}\")\n",
    "    trainer.train(resum_from_checkpoint=last_checkpoint)\n",
    "else:\n",
    "    print(\"Training from scratch\")\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T22:48:15.234311Z",
     "iopub.status.busy": "2025-04-02T22:48:15.233978Z",
     "iopub.status.idle": "2025-04-02T22:48:15.424220Z",
     "shell.execute_reply": "2025-04-02T22:48:15.423554Z",
     "shell.execute_reply.started": "2025-04-02T22:48:15.234281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_TOKEN'] = 'MY_TOKEN'\n",
    "login(token=os.getenv('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "last_checkpoint = None\n",
    "\n",
    "if os.path.isdir(\"./nllb200-finetuned-checkpoints\"):\n",
    "    checkpoints = [os.path.join(\"./nllb200-finetuned-checkpoints\", d) for d in os.listdir(\"./nllb200-finetuned-checkpoints\") if d.startswith(\"checkpoint\")]\n",
    "\n",
    "    if checkpoints:\n",
    "        last_checkpoint = sorted(checkpoints, key = lambda x : int(x.split(\"-\")[-1]))[-1]\n",
    "\n",
    "if last_checkpoint:\n",
    "    print(f\"Load {last_checkpoint}\")\n",
    "    modelPath = os.path.join(\"nllb200-finetuned-checkpoints\", last_checkpoint)\n",
    "    \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(modelPath)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(modelPath, tgt_lang=\"vie_Latn\")\n",
    "\n",
    "    model.push_to_hub(\"phuckhangne/nllb-200-600M-GDGoC-AI-Challenge\")\n",
    "    tokenizer.push_to_hub(\"phuckhangne/nllb-200-600M-GDGoC-AI-Challenge\")\n",
    "else:\n",
    "    print('Get error in loading model')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
